"""
ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯å¯¾ç­–ã‚’å¼·åŒ–ã—ãŸ frame_restorer.py
VRAMæœ€é©åŒ–ç‰ˆ
"""

import logging
import queue
import threading
import time
import textwrap
from typing import Optional
from concurrent.futures import ThreadPoolExecutor
from collections import defaultdict
import heapq

import cv2
import numpy as np
import torch

from lada import LOG_LEVEL
from lada.lib import image_utils, video_utils, threading_utils, mask_utils
from lada.lib import visualization_utils
from lada.lib.mosaic_detector import MosaicDetector
from lada.lib.mosaic_detection_model import MosaicDetectionModel

logger = logging.getLogger(__name__)
logging.basicConfig(level=LOG_LEVEL)

# ====================================
# è¨ºæ–­ã‚¯ãƒ©ã‚¹ç¾¤
# ====================================

class ParallelDiagnostics:
    """ä¸¦åˆ—å‡¦ç†ã®ç¨¼åƒçŠ¶æ³ã‚’è¨ºæ–­"""
    
    def __init__(self):
        self.worker_stats = defaultdict(lambda: {
            'clips_processed': 0,
            'total_time': 0,
            'wait_time': 0,
            'gpu_time': 0,
            'last_activity': 0
        })
        self.queue_stats = []
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def record_worker_start(self, worker_id):
        with self.lock:
            self.worker_stats[worker_id]['last_activity'] = time.time()
    
    def record_worker_processing(self, worker_id, clip_frames, processing_time):
        with self.lock:
            stats = self.worker_stats[worker_id]
            stats['clips_processed'] += 1
            stats['gpu_time'] += processing_time
            stats['last_activity'] = time.time()
    
    def record_worker_wait(self, worker_id, wait_time):
        with self.lock:
            self.worker_stats[worker_id]['wait_time'] += wait_time
    
    def record_queue_size(self, queue_name, size):
        self.queue_stats.append({
            'time': time.time() - self.start_time,
            'queue': queue_name,
            'size': size
        })
    
    def get_report(self):
        with self.lock:
            total_elapsed = time.time() - self.start_time
            
            report = ["=" * 60]
            report.append("ä¸¦åˆ—å‡¦ç†è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ")
            report.append("=" * 60)
            report.append(f"çµŒéæ™‚é–“: {total_elapsed:.2f}ç§’")
            report.append("")
            
            report.append("ãƒ¯ãƒ¼ã‚«ãƒ¼çµ±è¨ˆ:")
            report.append("-" * 60)
            
            active_workers = 0
            total_clips = 0
            for worker_id, stats in sorted(self.worker_stats.items()):
                idle_time = time.time() - stats['last_activity']
                is_active = idle_time < 5.0
                
                if is_active:
                    active_workers += 1
                
                total_clips += stats['clips_processed']
                
                status = "ğŸŸ¢ ç¨¼åƒä¸­" if is_active else "ğŸ”´ å¾…æ©Ÿ"
                report.append(
                    f"{worker_id}: {status} | "
                    f"å‡¦ç†: {stats['clips_processed']} | "
                    f"GPU: {stats['gpu_time']:.1f}s | "
                    f"å¾…æ©Ÿ: {stats['wait_time']:.1f}s"
                )
            
            report.append("")
            report.append(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚«ãƒ¼: {active_workers}/{len(self.worker_stats)}")
            report.append(f"ç·å‡¦ç†ã‚¯ãƒªãƒƒãƒ—æ•°: {total_clips}")
            
            total_gpu_time = sum(s['gpu_time'] for s in self.worker_stats.values())
            total_wait_time = sum(s['wait_time'] for s in self.worker_stats.values())
            
            if total_elapsed > 0 and len(self.worker_stats) > 0:
                gpu_utilization = (total_gpu_time / (total_elapsed * len(self.worker_stats))) * 100
                wait_ratio = (total_wait_time / (total_elapsed * len(self.worker_stats))) * 100
                
                report.append("")
                report.append(f"ä¸¦åˆ—åŠ¹ç‡:")
                report.append(f"  GPUåˆ©ç”¨ç‡: {gpu_utilization:.1f}%")
                report.append(f"  å¾…æ©Ÿæ™‚é–“: {wait_ratio:.1f}%")
                
                if gpu_utilization < 20:
                    report.append("  âš ï¸ GPUåˆ©ç”¨ç‡ãŒä½ã„ - ä¸¦åˆ—å‡¦ç†ãŒæ©Ÿèƒ½ã—ã¦ã„ãªã„å¯èƒ½æ€§")
                if active_workers < len(self.worker_stats) * 0.5:
                    report.append("  âš ï¸ ç¨¼åƒãƒ¯ãƒ¼ã‚«ãƒ¼ãŒå°‘ãªã„ - ã‚­ãƒ¥ãƒ¼ãŒç©ºã®å¯èƒ½æ€§")
            
            report.append("=" * 60)
            
            return "\n".join(report)


class QueueMonitor:
    """ã‚­ãƒ¥ãƒ¼ã®è©°ã¾ã‚Šã‚’ç›£è¦–"""
    
    def __init__(self, queue_obj, name, warning_threshold=0.8):
        self.queue = queue_obj
        self.name = name
        self.warning_threshold = warning_threshold
        self.last_check = time.time()
        self.stall_count = 0
    
    def check(self):
        now = time.time()
        if now - self.last_check > 5.0:
            if self.queue.maxsize > 0:
                usage = self.queue.qsize() / self.queue.maxsize
                
                if usage > self.warning_threshold:
                    self.stall_count += 1
                    logger.warning(
                        f"âš ï¸ {self.name}ãŒ{usage*100:.0f}%æº€æ¯ "
                        f"(åœæ»: {self.stall_count})"
                    )
            
            self.last_check = now

def load_models(device, mosaic_restoration_model_name, mosaic_restoration_model_path, mosaic_restoration_config_path, mosaic_detection_model_path):
    if mosaic_restoration_model_name.startswith("deepmosaics"):
        from lada.deepmosaics.models import loadmodel, model_util
        mosaic_restoration_model = loadmodel.video(model_util.device_to_gpu_id(device), mosaic_restoration_model_path)
        pad_mode = 'reflect'
    elif mosaic_restoration_model_name.startswith("basicvsrpp"):
        from lada.basicvsrpp.inference import load_model, get_default_gan_inference_config
        if mosaic_restoration_config_path:
            config = mosaic_restoration_config_path
        else:
            config = get_default_gan_inference_config()
        mosaic_restoration_model = load_model(config, mosaic_restoration_model_path, device)
        pad_mode = 'zero'
    else:
        raise NotImplementedError()
    mosaic_detection_model = MosaicDetectionModel(mosaic_detection_model_path, device, classes=[0], conf=0.2)
    return mosaic_detection_model, mosaic_restoration_model, pad_mode

# ====================================
# åŸºæœ¬FrameRestorerã‚¯ãƒ©ã‚¹
# ====================================

class FrameRestorer:
    def __init__(self, device, video_file, preserve_relative_scale, max_clip_length, mosaic_restoration_model_name,
                 mosaic_detection_model, mosaic_restoration_model, preferred_pad_mode,
                 mosaic_detection=False):
        """
        åŸºæœ¬FrameRestorerã‚¯ãƒ©ã‚¹ - æ—§ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç¶­æŒ
        """
        logger.info(f"ğŸ¯ FrameRestoreråˆæœŸåŒ– (preserve_relative_scale={preserve_relative_scale} - ç„¡è¦–ã•ã‚Œã¾ã™)")
        
        self.device = device
        self.mosaic_restoration_model_name = mosaic_restoration_model_name
        self.max_clip_length = max_clip_length
        self.video_file = video_file
        self.video_meta_data = video_utils.get_video_meta_data(video_file)
        self.mosaic_detection_model = mosaic_detection_model
        self.mosaic_restoration_model = mosaic_restoration_model
        self.preferred_pad_mode = preferred_pad_mode
        self.start_ns = 0
        self.start_frame = 0
        self.mosaic_detection = mosaic_detection
        self.eof = False
        self.stop_requested = False

        # ã‚­ãƒ¥ãƒ¼ã®åˆæœŸåŒ–
        max_frames_in_frame_restoration_queue = (512 * 1024 * 1024) // (self.video_meta_data.video_width * self.video_meta_data.video_height * 3)
        self.frame_restoration_queue = queue.Queue(maxsize=max_frames_in_frame_restoration_queue)

        max_clips_in_mosaic_clips_queue = max(1, (512 * 1024 * 1024) // (self.max_clip_length * 256 * 256 * 4))
        logger.debug(f"Set queue size of queue mosaic_clip_queue to {max_clips_in_mosaic_clips_queue}")
        self.mosaic_clip_queue = queue.Queue(maxsize=max_clips_in_mosaic_clips_queue)

        max_clips_in_restored_clips_queue = max(1, (512 * 1024 * 1024) // (self.max_clip_length * 256 * 256 * 4))
        logger.debug(f"Set queue size of queue restored_clip_queue to {max_clips_in_restored_clips_queue}")
        self.restored_clip_queue = queue.Queue(maxsize=max_clips_in_restored_clips_queue)

        self.frame_detection_queue = queue.Queue()

        # æ–°ã—ã„MosaicDetectorã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        logger.info("ğŸ”„ MosaicDetectorã‚’åˆæœŸåŒ–ä¸­...")
        try:
            self.mosaic_detector = MosaicDetector(
                self.mosaic_detection_model, 
                self.video_file,
                frame_detection_queue=self.frame_detection_queue,
                mosaic_clip_queue=self.mosaic_clip_queue,
                device=self.device,
                max_clip_length=self.max_clip_length,
                pad_mode=self.preferred_pad_mode
            )
            logger.info("âœ… MosaicDetectoråˆæœŸåŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ MosaicDetectoråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        self.clip_restoration_thread = None
        self.frame_restoration_thread = None
        self.clip_restoration_thread_should_be_running = False
        self.frame_restoration_thread_should_be_running = False

        self.queue_stats = {}
        self.queue_stats["restored_clip_queue_max_size"] = 0
        self.queue_stats["restored_clip_queue_wait_time_put"] = 0
        self.queue_stats["restored_clip_queue_wait_time_get"] = 0
        self.queue_stats["mosaic_clip_queue_wait_time_get"] = 0
        self.queue_stats["frame_restoration_queue_max_size"] = 0
        self.queue_stats["frame_restoration_queue_wait_time_get"] = 0
        self.queue_stats["frame_restoration_queue_wait_time_put"] = 0
        self.queue_stats["frame_detection_queue_wait_time_get"] = 0

        logger.info(f"âœ… FrameRestoreråˆæœŸåŒ–å®Œäº†:")
        logger.info(f"  - ãƒ“ãƒ‡ã‚ª: {self.video_file}")
        logger.info(f"  - è§£åƒåº¦: {self.video_meta_data.video_width}x{self.video_meta_data.video_height}")
        logger.info(f"  - æœ€å¤§ã‚¯ãƒªãƒƒãƒ—é•·: {self.max_clip_length}")

    def start(self, start_ns=0):
        logger.info(f"ğŸš€ FrameRestoreré–‹å§‹: start_ns={start_ns}")
        
        assert self.frame_restoration_thread is None and self.clip_restoration_thread is None
        assert self.mosaic_clip_queue.empty()
        assert self.restored_clip_queue.empty()
        assert self.frame_detection_queue.empty()
        assert self.frame_restoration_queue.empty()

        self.start_ns = start_ns
        self.start_frame = video_utils.offset_ns_to_frame_num(self.start_ns, self.video_meta_data.video_fps_exact)
        self.stop_requested = False
        self.frame_restoration_thread_should_be_running = True
        self.clip_restoration_thread_should_be_running = True

        self.frame_restoration_thread = threading.Thread(target=self._frame_restoration_worker)
        self.clip_restoration_thread = threading.Thread(target=self._clip_restoration_worker)

        logger.info("ğŸ”„ MosaicDetectorã‚’é–‹å§‹ä¸­...")
        self.mosaic_detector.start(start_ns=start_ns)
        self.clip_restoration_thread.start()
        self.frame_restoration_thread.start()

        logger.info("âœ… FrameRestoreré–‹å§‹å®Œäº†")

    def stop(self):
        logger.debug("FrameRestorer: åœæ­¢ä¸­...")
        start = time.time()
        self.stop_requested = True
        self.clip_restoration_thread_should_be_running = False
        self.frame_restoration_thread_should_be_running = False

        self.mosaic_detector.stop()

        threading_utils.put_closing_queue_marker(self.mosaic_clip_queue, "mosaic_clip_queue")
        threading_utils.empty_out_queue(self.restored_clip_queue, "restored_clip_queue")
        if self.clip_restoration_thread:
            self.clip_restoration_thread.join()
            logger.debug("clip restoration worker: stopped")
        self.clip_restoration_thread = None

        threading_utils.put_closing_queue_marker(self.frame_detection_queue, "frame_detection_queue")
        threading_utils.put_closing_queue_marker(self.restored_clip_queue, "restored_clip_queue")
        threading_utils.empty_out_queue(self.frame_restoration_queue, "frame_restoration_queue")
        if self.frame_restoration_thread:
            self.frame_restoration_thread.join()
            logger.debug("frame restoration worker: stopped")
        self.frame_restoration_thread = None

        threading_utils.empty_out_queue(self.mosaic_clip_queue, "mosaic_clip_queue")
        threading_utils.empty_out_queue(self.restored_clip_queue, "restored_clip_queue")
        threading_utils.empty_out_queue(self.frame_detection_queue, "frame_detection_queue")
        threading_utils.empty_out_queue(self.frame_restoration_queue, "frame_restoration_queue")

        assert self.mosaic_clip_queue.empty()
        assert self.restored_clip_queue.empty()
        assert self.frame_detection_queue.empty()
        assert self.frame_restoration_queue.empty()

        logger.debug(f"FrameRestorer: åœæ­¢å®Œäº†, æ‰€è¦æ™‚é–“: {time.time() - start}")

    def _restore_clip_frames(self, images):
        if self.mosaic_restoration_model_name.startswith("deepmosaics"):
            from lada.deepmosaics.inference import restore_video_frames
            from lada.deepmosaics.models import model_util
            restored_clip_images = restore_video_frames(model_util.device_to_gpu_id(self.device), self.mosaic_restoration_model, images)
        elif self.mosaic_restoration_model_name.startswith("basicvsrpp"):
            from lada.basicvsrpp.inference import inference
            restored_clip_images = inference(self.mosaic_restoration_model, images, self.device)
        else:
            raise NotImplementedError()
        return restored_clip_images

    def _restore_frame(self, frame, frame_num, restored_clips):
        for buffered_clip in [c for c in restored_clips if c.frame_start == frame_num]:
            clip_img, clip_mask, orig_clip_box, orig_crop_shape, pad_after_resize = buffered_clip.pop()
            clip_img = image_utils.unpad_image(clip_img, pad_after_resize)
            clip_mask = image_utils.unpad_image(clip_mask, pad_after_resize)
            clip_img = image_utils.resize(clip_img, orig_crop_shape[:2])
            clip_mask = image_utils.resize(clip_mask, orig_crop_shape[:2],interpolation=cv2.INTER_NEAREST)
            t, l, b, r = orig_clip_box
            blend_mask = mask_utils.create_blend_mask(clip_mask)
            blended_img = (frame[t:b + 1, l:r + 1, :] * (1 - blend_mask[..., None]) + clip_img * (blend_mask[..., None])).clip(0, 255).astype(np.uint8)
            frame[t:b + 1, l:r + 1, :] = blended_img

    def _restore_clip(self, clip):
        if self.mosaic_detection:
            restored_clip_images = visualization_utils.draw_mosaic_detections(clip)
        else:
            images = clip.get_clip_images()
            restored_clip_images = self._restore_clip_frames(images)
        assert len(restored_clip_images) == len(clip.get_clip_images())

        for i in range(len(restored_clip_images)):
            assert clip.data[i][0].shape == restored_clip_images[i].shape
            clip.data[i] = restored_clip_images[i], clip.data[i][1], clip.data[i][2], clip.data[i][3], clip.data[i][4]

    def _collect_garbage(self, clip_buffer):
        processed_clips = list(filter(lambda _clip: len(_clip) == 0, clip_buffer))
        for processed_clip in processed_clips:
            clip_buffer.remove(processed_clip)

    def _contains_at_least_one_clip_starting_after_frame_num(self, frame_num, clip_buffer):
        return len(clip_buffer) > 0 and frame_num < max(clip_buffer, key=lambda c: c.frame_start).frame_start

    def _clip_restoration_worker(self):
        logger.debug("clip restoration worker: started")
        eof = False
        while self.clip_restoration_thread_should_be_running:
            s = time.time()
            clip = self.mosaic_clip_queue.get()
            self.queue_stats["mosaic_clip_queue_wait_time_get"] += time.time() - s
            if self.stop_requested:
                logger.debug("clip restoration worker: mosaic_clip_queue consumer unblocked")
            if clip is None:
                if not self.stop_requested:
                    eof = True
                    self.clip_restoration_thread_should_be_running = False
                    self.queue_stats["restored_clip_queue_max_size"] = max(self.restored_clip_queue.qsize()+1, self.queue_stats["restored_clip_queue_max_size"])
                    s = time.time()
                    self.restored_clip_queue.put(None)
                    self.queue_stats["restored_clip_queue_wait_time_put"] += time.time() -s
                    logger.debug("clip restoration worker: restored_clip_queue producer unblocked")
            else:
                self._restore_clip(clip)
                self.queue_stats["restored_clip_queue_max_size"] = max(self.restored_clip_queue.qsize()+1, self.queue_stats["restored_clip_queue_max_size"])
                s = time.time()
                self.restored_clip_queue.put(clip)
                self.queue_stats["restored_clip_queue_wait_time_put"] += time.time() - s
                if self.stop_requested:
                    logger.debug("clip restoration worker: restored_clip_queue producer unblocked")
        if eof:
            logger.debug("clip restoration worker: stopped itself, EOF")

    def _read_next_frame(self, video_frames_generator, expected_frame_num):
        try:
            frame, frame_pts = next(video_frames_generator)
        except StopIteration:
            s = time.time()
            elem = self.frame_detection_queue.get()
            self.queue_stats["frame_detection_queue_wait_time_get"] += time.time() - s
            if self.stop_requested:
                logger.debug("frame restoration worker: frame_detection_queue consumer unblocked")
            assert elem is None
            return None
        s = time.time()
        elem = self.frame_detection_queue.get()
        self.queue_stats["frame_detection_queue_wait_time_get"] += time.time() - s
        if self.stop_requested:
            logger.debug("frame restoration worker: frame_detection_queue consumer unblocked")
            return None
        assert elem is not None
        detection_frame_num, mosaic_detected = elem
        assert self.stop_requested or detection_frame_num == expected_frame_num
        return mosaic_detected, frame, frame_pts

    def _read_next_clip(self, current_frame_num, clip_buffer):
        s = time.time()
        clip = self.restored_clip_queue.get()
        self.queue_stats["restored_clip_queue_wait_time_get"] += time.time() - s
        if self.stop_requested:
            logger.debug("frame restoration worker: restored_clip_queue consumer unblocked")
        if clip is None:
            return False
        assert self.stop_requested or clip.frame_start >= current_frame_num
        clip_buffer.append(clip)
        return True

    def _frame_restoration_worker(self):
        logger.debug("frame restoration worker: started")
        with video_utils.VideoReader(self.video_file) as video_reader:
            if self.start_ns > 0:
                video_reader.seek(self.start_ns)

            video_frames_generator = video_reader.frames()

            frame_num = self.start_frame
            clips_remaining = True
            clip_buffer = []

            while self.frame_restoration_thread_should_be_running:
                _frame_result = self._read_next_frame(video_frames_generator, frame_num)
                if _frame_result is None:
                    if not self.stop_requested:
                        self.eof = True
                        self.frame_restoration_thread_should_be_running = False
                        self.frame_restoration_queue.put(None)
                    break
                else:
                    mosaic_detected, frame, frame_pts = _frame_result
                if mosaic_detected:
                    while clips_remaining and not self._contains_at_least_one_clip_starting_after_frame_num(frame_num, clip_buffer):
                        clips_remaining = self._read_next_clip(frame_num, clip_buffer)

                    self._restore_frame(frame, frame_num, clip_buffer)
                    self.queue_stats["frame_restoration_queue_max_size"] = max(self.frame_restoration_queue.qsize()+1, self.queue_stats["frame_restoration_queue_max_size"])
                    s = time.time()
                    self.frame_restoration_queue.put((frame, frame_pts))
                    self.queue_stats["frame_restoration_queue_wait_time_put"] += time.time() -s
                    if self.stop_requested:
                        logger.debug("frame restoration worker: frame_restoration_queue producer unblocked")
                    self._collect_garbage(clip_buffer)
                else:
                    self.queue_stats["frame_restoration_queue_max_size"] = max(self.frame_restoration_queue.qsize()+1, self.queue_stats["frame_restoration_queue_max_size"])
                    s = time.time()
                    self.frame_restoration_queue.put((frame, frame_pts))
                    self.queue_stats["frame_restoration_queue_wait_time_put"] += time.time() - s
                    if self.stop_requested:
                        logger.debug("frame restoration worker: frame_restoration_queue producer unblocked")
                frame_num += 1
            if self.eof:
                logger.debug("frame restoration worker: stopped itself, EOF")

    def __iter__(self):
        return self

    def __next__(self):
        if self.eof and self.frame_restoration_queue.empty():
            raise StopIteration
        else:
            while not self.stop_requested:
                s = time.time()
                elem = self.frame_restoration_queue.get()
                self.queue_stats["frame_restoration_queue_wait_time_get"] += time.time() -s
                if self.stop_requested:
                    logger.debug("frame_restoration_queue consumer unblocked")
                if elem is None and not self.stop_requested:
                    raise StopIteration
                return elem

    def get_frame_restoration_queue(self):
        return self.frame_restoration_queue

# ====================================
# VRAMæœ€é©åŒ–ç‰ˆFrameRestorer
# ====================================

class OptimizedFrameRestorer:
    """
    VRAMæœ€é©åŒ–ç‰ˆFrameRestorer - ä¸¦åˆ—å‡¦ç†ã¨VRAMç®¡ç†ã‚’å¼·åŒ–
    """
    def __init__(self, device, video_file, preserve_relative_scale, max_clip_length,
                 mosaic_restoration_model_name, mosaic_detection_model, mosaic_restoration_model,
                 preferred_pad_mode, mosaic_detection=False, batch_size=16, parallel_clips=4,
                 enable_vram_direct=True, dynamic_batch_size=True, auto_worker_count=False,
                 enable_diagnostics=True):
        """
        VRAMæœ€é©åŒ–ç‰ˆ - ä¸¦åˆ—å‡¦ç†ã¨ãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’å¼·åŒ–
        """
        logger.info(f"ğŸ¯ OptimizedFrameRestoreråˆæœŸåŒ– (VRAMæœ€é©åŒ–ç‰ˆ):")
        logger.info(f"  - batch_size: {batch_size}")
        logger.info(f"  - parallel_clips: {parallel_clips}")
        logger.info(f"  - enable_vram_direct: {enable_vram_direct}")
        
        self.device = device
        self.mosaic_restoration_model_name = mosaic_restoration_model_name
        self.max_clip_length = max_clip_length
        self.video_file = video_file
        self.video_meta_data = video_utils.get_video_meta_data(video_file)
        self.mosaic_detection_model = mosaic_detection_model
        self.mosaic_restoration_model = mosaic_restoration_model
        self.preferred_pad_mode = preferred_pad_mode
        self.start_ns = 0
        self.start_frame = 0
        self.mosaic_detection = mosaic_detection
        self.eof = False
        self.stop_requested = False

        # VRAMæœ€é©åŒ–è¨­å®š
        self.batch_size = batch_size
        self.parallel_clips = parallel_clips
        self.enable_vram_direct = enable_vram_direct
        self.dynamic_batch_size = dynamic_batch_size
        self.auto_worker_count = auto_worker_count
        self.enable_diagnostics = enable_diagnostics

        if auto_worker_count:
            self.parallel_clips = self._calculate_optimal_workers()

        # ã‚­ãƒ¥ãƒ¼ã®åˆæœŸåŒ–ï¼ˆVRAMæœ€é©åŒ–ï¼‰
        max_frames_in_frame_restoration_queue = (512 * 1024 * 1024) // (
            self.video_meta_data.video_width * self.video_meta_data.video_height * 3
        )
        self.frame_restoration_queue = queue.Queue(maxsize=max_frames_in_frame_restoration_queue)

        max_clips_in_mosaic_clips_queue = max(
            self.parallel_clips * 2,
            (512 * 1024 * 1024) // (self.max_clip_length * 256 * 256 * 4)
        )
        self.mosaic_clip_queue = queue.Queue(maxsize=max_clips_in_mosaic_clips_queue)

        max_clips_in_restored_clips_queue = max(
            self.parallel_clips * 2,
            (512 * 1024 * 1024) // (self.max_clip_length * 256 * 256 * 4)
        )
        self.restored_clip_queue = queue.Queue(maxsize=max_clips_in_restored_clips_queue)

        self.frame_detection_queue = queue.Queue()

        # ä¸¦åˆ—å‡¦ç†ç”¨ã‚­ãƒ¥ãƒ¼
        self.unordered_clips_queue = queue.Queue(maxsize=max_clips_in_restored_clips_queue * 2)
        self.next_expected_clip_id = 0
        self.clip_counter = 0
        self.clip_counter_lock = threading.Lock()

        # æ–°ã—ã„MosaicDetectorã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        logger.info("ğŸ”„ MosaicDetectorã‚’åˆæœŸåŒ–ä¸­...")
        try:
            self.mosaic_detector = MosaicDetector(
                self.mosaic_detection_model, 
                self.video_file,
                frame_detection_queue=self.frame_detection_queue,
                mosaic_clip_queue=self.mosaic_clip_queue,
                device=self.device,
                max_clip_length=self.max_clip_length,
                pad_mode=self.preferred_pad_mode
            )
            logger.info("âœ… MosaicDetectoråˆæœŸåŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ MosaicDetectoråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        # ä¸¦åˆ—å‡¦ç†ã‚¹ãƒ¬ãƒƒãƒ‰
        self.clip_executor = None
        self.clip_restoration_threads = []
        self.frame_restoration_thread = None
        self.clip_ordering_thread = None

        self.clip_restoration_threads_should_be_running = False
        self.frame_restoration_thread_should_be_running = False
        self.clip_ordering_thread_should_be_running = False

        # VRAMç®¡ç†
        self.workers_finished_count = 0
        self.workers_finished_lock = threading.Lock()

        # è¨ºæ–­æ©Ÿèƒ½
        if enable_diagnostics:
            self.diagnostics = ParallelDiagnostics()
            self.queue_monitors = {
                'mosaic_clip': QueueMonitor(self.mosaic_clip_queue, 'mosaic_clip_queue'),
                'restored_clip': QueueMonitor(self.restored_clip_queue, 'restored_clip_queue'),
            }
            logger.info("âœ… è¨ºæ–­æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–")
        else:
            self.diagnostics = None
            self.queue_monitors = {}

        self.queue_stats = {
            "restored_clip_queue_max_size": 0,
            "restored_clip_queue_wait_time_put": 0,
            "restored_clip_queue_wait_time_get": 0,
            "mosaic_clip_queue_wait_time_get": 0,
            "frame_restoration_queue_max_size": 0,
            "frame_restoration_queue_wait_time_get": 0,
            "frame_restoration_queue_wait_time_put": 0,
            "frame_detection_queue_wait_time_get": 0,
            "parallel_clips_processed": 0,
            "clip_wait_for_order": 0,
            "clip_timeout_count": 0,
            "clip_skipped_count": 0,
            "deadlock_recovery_count": 0,
        }

        logger.info(f"âœ… OptimizedFrameRestoreråˆæœŸåŒ–å®Œäº†:")
        logger.info(f"  - ä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.parallel_clips}")
        logger.info(f"  - ãƒãƒƒãƒã‚µã‚¤ã‚º: {self.batch_size}")
        logger.info(f"  - VRAMç›´æ¥å‡¦ç†: {'æœ‰åŠ¹' if enable_vram_direct else 'ç„¡åŠ¹'}")

    def _calculate_optimal_workers(self):
        """æœ€é©ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚’è¨ˆç®—"""
        if torch.cuda.is_available():
            total_vram = torch.cuda.get_device_properties(0).total_memory
            optimal_workers = max(1, int((total_vram * 0.7) / (1024**3)))
            return min(optimal_workers, 8)
        return 4

    def _get_next_clip_id(self):
        with self.clip_counter_lock:
            clip_id = self.clip_counter
            self.clip_counter += 1
            return clip_id

    def start(self, start_ns=0):
        logger.info(f"ğŸš€ OptimizedFrameRestoreré–‹å§‹: start_ns={start_ns}")
        
        self.start_ns = start_ns
        self.start_frame = video_utils.offset_ns_to_frame_num(
            self.start_ns, self.video_meta_data.video_fps_exact
        )
        self.stop_requested = False
        self.next_expected_clip_id = 0
        self.clip_counter = 0
        self.workers_finished_count = 0

        self.frame_restoration_thread_should_be_running = True
        self.clip_restoration_threads_should_be_running = True
        self.clip_ordering_thread_should_be_running = True

        # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        self.clip_executor = ThreadPoolExecutor(
            max_workers=self.parallel_clips,
            thread_name_prefix="ClipRestorer"
        )

        # MosaicDetectoré–‹å§‹
        self.mosaic_detector.start(start_ns=start_ns)

        # ä¸¦åˆ—ã‚¯ãƒªãƒƒãƒ—å‡¦ç†ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
        for i in range(self.parallel_clips):
            thread = threading.Thread(
                target=self._clip_restoration_worker_vram,
                name=f"ClipWorker-{i}"
            )
            thread.start()
            self.clip_restoration_threads.append(thread)

        # ã‚¯ãƒªãƒƒãƒ—é †åºä»˜ã‘ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
        self.clip_ordering_thread = threading.Thread(
            target=self._clip_ordering_worker_with_recovery,
            name="ClipOrderingWorker"
        )
        self.clip_ordering_thread.start()

        # ãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•
        self.frame_restoration_thread = threading.Thread(
            target=self._frame_restoration_worker_vram,
            name="FrameRestorationWorker"
        )
        self.frame_restoration_thread.start()

        logger.info(f"âœ… èµ·å‹•å®Œäº†: {self.parallel_clips} ãƒ¯ãƒ¼ã‚«ãƒ¼")

    def _clip_restoration_worker_vram(self):
        """VRAMæœ€é©åŒ–ç‰ˆã‚¯ãƒªãƒƒãƒ—å¾©å…ƒãƒ¯ãƒ¼ã‚«ãƒ¼"""
        worker_name = threading.current_thread().name
        logger.debug(f"{worker_name}: VRAMæœ€é©åŒ–ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•")
        
        error_count = 0
        max_errors = 10
        clips_processed = 0

        while self.clip_restoration_threads_should_be_running:
            if self.diagnostics:
                self.diagnostics.record_queue_size('mosaic_clip_queue', self.mosaic_clip_queue.qsize())
            
            try:
                wait_start = time.time()
                clip = self.mosaic_clip_queue.get(timeout=0.5)
                wait_time = time.time() - wait_start
                
                if self.diagnostics:
                    self.diagnostics.record_worker_wait(worker_name, wait_time)

                if clip is None:
                    logger.info(f"{worker_name}: EOFãƒãƒ¼ã‚«ãƒ¼å—ä¿¡ (å‡¦ç†æ•°: {clips_processed})")
                    
                    # EOFãƒãƒ¼ã‚«ãƒ¼ã‚’ä»–ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ãŸã‚ã«æˆ»ã™
                    self.mosaic_clip_queue.put(None)
                    
                    # å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼çµ‚äº†ã‚’å¾…ã£ã¦ã‹ã‚‰EOFãƒãƒ¼ã‚«ãƒ¼é€ä¿¡
                    with self.workers_finished_lock:
                        self.workers_finished_count += 1
                        finished_count = self.workers_finished_count
                        logger.info(f"{worker_name}: çµ‚äº† ({finished_count}/{self.parallel_clips})")
                        
                        # æœ€å¾Œã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã ã‘ãŒEOFãƒãƒ¼ã‚«ãƒ¼ã‚’é€ä¿¡
                        if finished_count == self.parallel_clips:
                            logger.info(f"{worker_name}: å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼çµ‚äº† - EOFãƒãƒ¼ã‚«ãƒ¼é€ä¿¡")
                            self.unordered_clips_queue.put(None)
                    
                    break

                clip_id = self._get_next_clip_id()
                clip_length = len(clip.get_clip_images())
                
                if self.diagnostics:
                    self.diagnostics.record_worker_start(worker_name)
                
                gpu_start = time.time()
                
                try:
                    # VRAMæœ€é©åŒ–å‡¦ç†
                    processed_clip = self._restore_clip_vram(clip)
                    
                    gpu_time = time.time() - gpu_start
                    
                    if self.diagnostics:
                        self.diagnostics.record_worker_processing(worker_name, clip_length, gpu_time)
                    
                    self.unordered_clips_queue.put((clip_id, processed_clip))
                    self.queue_stats['parallel_clips_processed'] += 1
                    clips_processed += 1
                    error_count = 0
                    
                except Exception as e:
                    logger.error(f"{worker_name}: ã‚¨ãƒ©ãƒ¼ (clip={clip_id}): {e}")
                    error_count += 1
                    if error_count >= max_errors:
                        break

            except queue.Empty:
                if self.stop_requested:
                    break
                continue

        logger.debug(f"{worker_name}: çµ‚äº† (åˆè¨ˆ: {clips_processed})")

    def _restore_clip_vram(self, clip):
        """VRAMæœ€é©åŒ–ç‰ˆã‚¯ãƒªãƒƒãƒ—å¾©å…ƒ"""
        if self.mosaic_detection:
            restored_clip_images = visualization_utils.draw_mosaic_detections(clip)
        else:
            images = clip.get_clip_images()
            # VRAMæœ€é©åŒ–å‡¦ç†
            restored_clip_images = self._restore_clip_frames_vram(images)

        assert len(restored_clip_images) == len(clip.get_clip_images())

        for i in range(len(restored_clip_images)):
            clip.data[i] = (
                restored_clip_images[i],
                clip.data[i][1],
                clip.data[i][2],
                clip.data[i][3],
                clip.data[i][4]
            )
        
        return clip

    def _restore_clip_frames_vram(self, images):
        """VRAMæœ€é©åŒ–ç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒ"""
        if self.mosaic_restoration_model_name.startswith("deepmosaics"):
            from lada.deepmosaics.inference import restore_video_frames
            from lada.deepmosaics.models import model_util
            restored_clip_images = restore_video_frames(
                model_util.device_to_gpu_id(self.device), 
                self.mosaic_restoration_model, 
                images
            )
            
        elif self.mosaic_restoration_model_name.startswith("basicvsrpp"):
            from lada.basicvsrpp.inference import inference
            
            # VRAMæœ€é©åŒ–: ãƒ†ãƒ³ã‚½ãƒ«ã‚’é©åˆ‡ã«å‡¦ç†
            numpy_images = []
            for img in images:
                if isinstance(img, torch.Tensor):
                    if img.is_cuda:
                        img = img.cpu()
                    if img.ndim == 3 and img.shape[0] == 3:
                        img = img.permute(1, 2, 0)
                    img = img.numpy()
                    if img.dtype == np.float32 and img.max() <= 1.0:
                        img = (img * 255).astype(np.uint8)
                    elif img.dtype != np.uint8:
                        img = img.astype(np.uint8)
                numpy_images.append(img)
            
            restored_clip_images = inference(
                self.mosaic_restoration_model, 
                numpy_images,
                self.device
            )
        else:
            raise NotImplementedError()
        
        return restored_clip_images

    def _clip_ordering_worker_with_recovery(self):
        """ã‚¯ãƒªãƒƒãƒ—é †åºä»˜ã‘ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ãƒªã‚«ãƒãƒªãƒ¼ä»˜ãï¼‰"""
        pending_clips = []
        eof = False
        last_progress_time = time.time()
        stall_threshold = 10.0
        last_log_time = time.time()

        while self.clip_ordering_thread_should_be_running:
            try:
                item = self.unordered_clips_queue.get(timeout=1.0)

                if item is None:
                    if not self.stop_requested:
                        eof = True
                        logger.info(
                            f"clip_ordering_worker: EOFå—ä¿¡ (pending={len(pending_clips)}, "
                            f"next_expected={self.next_expected_clip_id})"
                        )
                        break
                    else:
                        break

                clip_id, clip = item
                heapq.heappush(pending_clips, (clip_id, clip))

                # é€²æ—ãŒã‚ã£ãŸã‚‰æ™‚åˆ»æ›´æ–°
                made_progress = False
                while pending_clips and pending_clips[0][0] == self.next_expected_clip_id:
                    _, ordered_clip = heapq.heappop(pending_clips)
                    self.restored_clip_queue.put(ordered_clip)
                    self.next_expected_clip_id += 1
                    made_progress = True
                
                if made_progress:
                    last_progress_time = time.time()

            except queue.Empty:
                # ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯æ¤œå‡ºã¨ãƒªã‚«ãƒãƒªãƒ¼
                current_time = time.time()
                stall_duration = current_time - last_progress_time
                
                if stall_duration > stall_threshold:
                    if pending_clips:
                        expected_id = self.next_expected_clip_id
                        actual_id = pending_clips[0][0]
                        
                        if actual_id > expected_id:
                            logger.error(
                                f"ğŸš¨ ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯æ¤œçŸ¥! (åœæ»: {stall_duration:.1f}ç§’)\n"
                                f"   æœŸå¾…ID: {expected_id}\n"
                                f"   æ¬¡ã®ID: {actual_id}\n"
                                f"   ä¿ç•™: {len(pending_clips)}\n"
                                f"   â†’ ID {expected_id}~{actual_id-1} ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ"
                            )
                            
                            # æ¬ è½ã—ãŸã‚¯ãƒªãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—
                            skipped_count = actual_id - expected_id
                            self.queue_stats['clip_skipped_count'] += skipped_count
                            self.queue_stats['deadlock_recovery_count'] += 1
                            self.next_expected_clip_id = actual_id
                            last_progress_time = current_time
                
                # å®šæœŸçš„ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°å‡ºåŠ›
                if current_time - last_log_time > 5.0:
                    logger.debug(
                        f"[ORDER] å¾…æ©Ÿä¸­ - æœŸå¾…ID:{self.next_expected_clip_id}, "
                        f"ä¿ç•™:{len(pending_clips)}, "
                        f"Qã‚µã‚¤ã‚º:{self.unordered_clips_queue.qsize()}, "
                        f"åœæ»:{stall_duration:.1f}s"
                    )
                    last_log_time = current_time
                
                if self.stop_requested:
                    break
                continue

        if eof:
            logger.info(f"clip_ordering_worker: EOFå‡¦ç†é–‹å§‹ (pending={len(pending_clips)})")
            
            # EOFã§ã‚‚æ®‹ã‚Šã®ã‚¯ãƒªãƒƒãƒ—ã‚’å…¨ã¦å‡¦ç†
            while pending_clips:
                expected_id = self.next_expected_clip_id
                actual_id = pending_clips[0][0]
                
                if actual_id == expected_id:
                    _, ordered_clip = heapq.heappop(pending_clips)
                    self.restored_clip_queue.put(ordered_clip)
                    logger.debug(f"clip_ordering_worker: ã‚¯ãƒªãƒƒãƒ— {expected_id} é€å‡º(EOFå‡¦ç†ä¸­)")
                    self.next_expected_clip_id += 1
                
                elif actual_id > expected_id:
                    # ã‚¯ãƒªãƒƒãƒ—æ¬ è½ã‚’è­¦å‘Š
                    logger.warning(
                        f"âš ï¸ ã‚¯ãƒªãƒƒãƒ—é †åºã‚¨ãƒ©ãƒ¼(EOFæ™‚): ID {expected_id} ãŒæ¬ è½\n"
                        f"   æ¬¡ã®ã‚¯ãƒªãƒƒãƒ—ID: {actual_id}\n"
                        f"   ä¿ç•™ä¸­: {len(pending_clips)}\n"
                        f"   ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿã®ãŸã‚ç¶šè¡Œã—ã¾ã™"
                    )
                    # æ¬ è½ã—ãŸIDã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ
                    skipped_count = actual_id - expected_id
                    self.queue_stats['clip_skipped_count'] += skipped_count
                    self.next_expected_clip_id = actual_id
                
                else:
                    logger.error(f"âŒ ç•°å¸¸: æ—¢ã«é€å‡ºæ¸ˆã¿ã®ID {actual_id} ãŒæ®‹ã£ã¦ã„ã¾ã™")
                    heapq.heappop(pending_clips)
            
            self.restored_clip_queue.put(None)
            logger.info("clip_ordering_worker: EOFãƒãƒ¼ã‚«ãƒ¼é€å‡ºå®Œäº†")

    def _frame_restoration_worker_vram(self):
        """VRAMæœ€é©åŒ–ç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒãƒ¯ãƒ¼ã‚«ãƒ¼"""
        logger.debug("frame restoration worker: started (VRAMæœ€é©åŒ–ç‰ˆ)")
        with video_utils.VideoReader(self.video_file) as video_reader:
            if self.start_ns > 0:
                video_reader.seek(self.start_ns)

            video_frames_generator = video_reader.frames()
            frame_num = self.start_frame
            clips_remaining = True
            clip_buffer = []

            while self.frame_restoration_thread_should_be_running:
                _frame_result = self._read_next_frame(video_frames_generator, frame_num)
                if _frame_result is None:
                    if not self.stop_requested:
                        self.eof = True
                        self.frame_restoration_queue.put(None)
                    break

                mosaic_detected, frame, frame_pts = _frame_result

                if mosaic_detected:
                    while clips_remaining and not self._contains_at_least_one_clip_starting_after_frame_num(
                        frame_num, clip_buffer
                    ):
                        clips_remaining = self._read_next_clip(frame_num, clip_buffer)

                    self._restore_frame(frame, frame_num, clip_buffer)
                    self._collect_garbage(clip_buffer)

                self.frame_restoration_queue.put((frame, frame_pts))
                frame_num += 1

    def _read_next_frame(self, video_frames_generator, expected_frame_num):
        try:
            frame, frame_pts = next(video_frames_generator)
        except StopIteration:
            elem = self.frame_detection_queue.get()
            assert elem is None
            return None
        
        elem = self.frame_detection_queue.get()
        if self.stop_requested:
            return None
        assert elem is not None
        detection_frame_num, mosaic_detected = elem
        return mosaic_detected, frame, frame_pts

    def _read_next_clip(self, current_frame_num, clip_buffer):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã®è‡ªå‹•ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½"""
        try:
            clip = self.restored_clip_queue.get(timeout=5.0)
            if self.stop_requested or clip is None:
                return False
            clip_buffer.append(clip)
            return True
        except queue.Empty:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚ã®å‡¦ç†
            timeout_count = self.queue_stats["clip_timeout_count"]
            self.queue_stats["clip_timeout_count"] += 1
            
            logger.warning(
                f"âš ï¸ ã‚¯ãƒªãƒƒãƒ—å–å¾—ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (frame={current_frame_num}, count={timeout_count+1})\n"
                f"   ãƒãƒƒãƒ•ã‚¡å†…: {len(clip_buffer)}, æ¬¡æœŸå¾…ID: {self.next_expected_clip_id}"
            )
            
            # é€£ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§ã‚¹ã‚­ãƒƒãƒ—
            if timeout_count >= 3:
                logger.error(
                    f"ğŸš¨ é€£ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ¤œçŸ¥ (count={timeout_count+1})\n"
                    f"   â†’ ã‚¯ãƒªãƒƒãƒ—å¾…ã¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œ"
                )
                return False  # ã‚¯ãƒªãƒƒãƒ—å¾…ã¡ã‚’è«¦ã‚ã‚‹
            
            return True  # ã¾ã ãƒªãƒˆãƒ©ã‚¤

    def _restore_frame(self, frame, frame_num, restored_clips):
        for buffered_clip in [c for c in restored_clips if c.frame_start == frame_num]:
            clip_img, clip_mask, orig_clip_box, orig_crop_shape, pad_after_resize = buffered_clip.pop()
            clip_img = image_utils.unpad_image(clip_img, pad_after_resize)
            clip_mask = image_utils.unpad_image(clip_mask, pad_after_resize)
            clip_img = image_utils.resize(clip_img, orig_crop_shape[:2])
            clip_mask = image_utils.resize(clip_mask, orig_crop_shape[:2], interpolation=cv2.INTER_NEAREST)
            t, l, b, r = orig_clip_box
            blend_mask = mask_utils.create_blend_mask(clip_mask)
            blended_img = (
                frame[t:b + 1, l:r + 1, :] * (1 - blend_mask[..., None]) +
                clip_img * (blend_mask[..., None])
            ).clip(0, 255).astype(np.uint8)
            frame[t:b + 1, l:r + 1, :] = blended_img

    def _collect_garbage(self, clip_buffer):
        processed_clips = list(filter(lambda _clip: len(_clip) == 0, clip_buffer))
        for processed_clip in processed_clips:
            clip_buffer.remove(processed_clip)

    def _contains_at_least_one_clip_starting_after_frame_num(self, frame_num, clip_buffer):
        return len(clip_buffer) > 0 and frame_num < max(clip_buffer, key=lambda c: c.frame_start).frame_start

    def stop(self):
        """VRAMæœ€é©åŒ–ç‰ˆåœæ­¢å‡¦ç†"""
        logger.debug("OptimizedFrameRestorer: åœæ­¢ä¸­...")
        start = time.time()
        
        if hasattr(self, 'diagnostics') and self.diagnostics is not None:
            import sys
            print("\n" + "="*70, file=sys.stdout)
            print("ğŸ“Š ä¸¦åˆ—å‡¦ç†è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆ", file=sys.stdout)
            print("="*70, file=sys.stdout)
            try:
                report = self.diagnostics.get_report()
                print(report, file=sys.stdout)
                sys.stdout.flush()
            except Exception as e:
                print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            print("="*70 + "\n", file=sys.stdout)
            sys.stdout.flush()
        
        self.stop_requested = True
        self.clip_restoration_threads_should_be_running = False
        self.frame_restoration_thread_should_be_running = False
        self.clip_ordering_thread_should_be_running = False

        self.mosaic_detector.stop()

        # å…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã«åœæ­¢ã‚·ã‚°ãƒŠãƒ«ã‚’é€ä¿¡
        for _ in range(self.parallel_clips):
            threading_utils.put_closing_queue_marker(self.mosaic_clip_queue, "mosaic_clip_queue")

        threading_utils.empty_out_queue(self.unordered_clips_queue, "unordered_clips_queue")

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã®çµ‚äº†ã‚’å¾…æ©Ÿ
        for thread in self.clip_restoration_threads:
            if thread:
                thread.join(timeout=2.0)
        self.clip_restoration_threads.clear()
        logger.debug("clip restoration workers: stopped")

        # ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ—ãƒ¼ãƒ«ã®ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
        if self.clip_executor:
            self.clip_executor.shutdown(wait=True, cancel_futures=True)
            self.clip_executor = None

        # é †åºä»˜ã‘ãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµ‚äº†
        threading_utils.put_closing_queue_marker(self.unordered_clips_queue, "unordered_clips_queue")
        threading_utils.empty_out_queue(self.restored_clip_queue, "restored_clip_queue")

        if self.clip_ordering_thread:
            self.clip_ordering_thread.join(timeout=2.0)
            self.clip_ordering_thread = None
        logger.debug("clip ordering worker: stopped")

        # ãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒãƒ¯ãƒ¼ã‚«ãƒ¼ã®çµ‚äº†
        threading_utils.put_closing_queue_marker(self.frame_detection_queue, "frame_detection_queue")
        threading_utils.put_closing_queue_marker(self.restored_clip_queue, "restored_clip_queue")
        threading_utils.empty_out_queue(self.frame_restoration_queue, "frame_restoration_queue")

        if self.frame_restoration_thread:
            self.frame_restoration_thread.join(timeout=2.0)
            self.frame_restoration_thread = None
        logger.debug("frame restoration worker: stopped")

        # VRAMè§£æ”¾
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # å…¨ã‚­ãƒ¥ãƒ¼ã®ã‚¯ãƒªã‚¢
        threading_utils.empty_out_queue(self.mosaic_clip_queue, "mosaic_clip_queue")
        threading_utils.empty_out_queue(self.restored_clip_queue, "restored_clip_queue")
        threading_utils.empty_out_queue(self.frame_detection_queue, "frame_detection_queue")
        threading_utils.empty_out_queue(self.frame_restoration_queue, "frame_restoration_queue")
        threading_utils.empty_out_queue(self.unordered_clips_queue, "unordered_clips_queue")

        logger.debug(f"OptimizedFrameRestorer: åœæ­¢å®Œäº†, æ‰€è¦æ™‚é–“: {time.time() - start:.2f}s")
        
        # çµ±è¨ˆå‡ºåŠ›
        logger.info(f"ğŸ“ˆ å‡¦ç†çµ±è¨ˆ:")
        logger.info(f"   ä¸¦åˆ—ã‚¯ãƒªãƒƒãƒ—å‡¦ç†æ•°: {self.queue_stats.get('parallel_clips_processed', 0)}")
        logger.info(f"   ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå›æ•°: {self.queue_stats.get('clip_timeout_count', 0)}")
        logger.info(f"   ã‚¹ã‚­ãƒƒãƒ—å›æ•°: {self.queue_stats.get('clip_skipped_count', 0)}")
        logger.info(f"   ãƒªã‚«ãƒãƒªãƒ¼å›æ•°: {self.queue_stats.get('deadlock_recovery_count', 0)}")

    def __iter__(self):
        return self

    def __next__(self):
        if self.eof and self.frame_restoration_queue.empty():
            raise StopIteration
        while not self.stop_requested:
            elem = self.frame_restoration_queue.get()
            if self.stop_requested:
                return None
            if elem is None and not self.stop_requested:
                raise StopIteration
            return elem

    def get_frame_restoration_queue(self):
        return self.frame_restoration_queue
